{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset... ok\n",
      "Creating train and validation datasets... ok\n",
      "Splitting dataset... ok\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', index_col='ID')\n",
    "print(\"Loading dataset... ok\")\n",
    "\n",
    "X, y = xy_split(df)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=57)\n",
    "print(\"Creating train and validation datasets... ok\")\n",
    "\n",
    "# Split dataset into to 2 dataframes (one with many NaNs, another with few NaNs)\n",
    "X_full, X_nan, y_full, y_nan, idx_full, idx_nan = preprocess(X_train, y_train)\n",
    "print(\"Splitting dataset... ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing Full Model... ok\n",
      "Reducing NaN Model... ok\n"
     ]
    }
   ],
   "source": [
    "pipe_full = Pipeline([\n",
    "    ('imputer', DataFrameImputer()),\n",
    "    ('dummyfier', Dummyfier()),\n",
    "    ('pca', PCA(n_components=25, svd_solver='arpack')),\n",
    "    # ('clf', RandomForestClassifier(n_estimators=10, max_depth=4)),\n",
    "])\n",
    "pipe_nan = Pipeline([\n",
    "    ('imputer', DataFrameImputer()),\n",
    "    ('dummyfier', Dummyfier()),\n",
    "    ('pca', PCA(n_components=25, svd_solver='arpack')),\n",
    "    # ('clf', RandomForestClassifier(n_estimators=10, max_depth=4)),\n",
    "])\n",
    "\n",
    "pipe_full.fit(X_full, y_full)\n",
    "print(\"Reducing Full Model... ok\")\n",
    "pipe_nan.fit(X_nan, y_nan)\n",
    "print(\"Reducing NaN Model... ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfs_full = [\n",
    "    ('rf25', RandomForestClassifier(n_estimators=25, max_depth=4, n_jobs=3)), \n",
    "    ('rf40', RandomForestClassifier(n_estimators=40, max_depth=3, n_jobs=3)),\n",
    "    ('logreg1', LogisticRegression(C=1.0)),\n",
    "    ('logreg3', LogisticRegression(C=3.0)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_estimator(est):\n",
    "    return est.__class__(**est.get_params(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StackingClassifier():\n",
    "    def __init__(self, probas_clfs, final_clf, transformer=None, k=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            probas_clfs (list of tuples): list of estimators to predict the probabilities, it takes to form of a list of tuple `[('est1_name', est1), ('est2_name', est2), ...]`\n",
    "            final_clf: the final classifier, trained over the intermediate probabilities\n",
    "            transformer (sklearn.base.TransformerMixin): object that processes transformations over the dataset (dummyfication, PCA, etc.)\n",
    "            k (int): number of folds in the CV process\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.transformer = transformer\n",
    "        # we need an independent set of estimators for each fold of the CV for the 1st level model\n",
    "        self.probas_clfs = [[(name, copy_estimator(clf)) for name, clf in probas_clfs] for _ in range(self.k)]\n",
    "        self.final_clf = final_clf\n",
    "        self._transformer_fitted = transformer is None\n",
    "        self._skf = StratifiedKFold(n_splits=self.k)\n",
    "        self._layer_fitted = False\n",
    "        self._layer_probas = None\n",
    "        self._final_fitted = False\n",
    "    \n",
    "    def _fit_transformer(self, X, y=None):\n",
    "        if self.transformer is not None:\n",
    "            self.transformer.fit(X, y)\n",
    "            self._transformer_fitted = True\n",
    "    \n",
    "    def _transform(self, X):\n",
    "        if not self._transformer_fitted:\n",
    "            raise Exception(\"Transformer not fitted.\")\n",
    "        return X if self.transformer is None else self.transformer.transform(X)\n",
    "    \n",
    "    def _fit_layer(self, X, y):\n",
    "        probas = np.zeros((y.shape[0], len(self.probas_clfs[0])))\n",
    "        for i, (train_idx, test_idx) in enumerate(self._skf.split(X, y)):\n",
    "            print(\"Fold %d/%d\" % (i + 1, len(self.probas_clfs)))\n",
    "            for j, (clf_name, clf) in enumerate(self.probas_clfs[i]):\n",
    "                print(\"    Estimator '%s'\" % (clf_name))\n",
    "                clf.fit(self._transform(X.iloc[train_idx]), y.iloc[train_idx])\n",
    "                probas[test_idx, j] = clf.predict_proba(self._transform(X.iloc[test_idx]))[:, 1]\n",
    "        self._layer_fitted = True\n",
    "        return probas\n",
    "\n",
    "    def _predict_layer_probas(self, X):\n",
    "        if not self._layer_fitted:\n",
    "            raise Exception(\"Intermediate estimators not fitted.\")\n",
    "        probas = np.empty((X.shape[0], len(self.probas_clfs[0]), self.k))\n",
    "        for i in range(self.k):\n",
    "            for j, (_, c) in enumerate(self.probas_clfs[i]):\n",
    "                probas[:, j, i] = c.predict_proba(self._transform(X))[:, 1]\n",
    "        return np.mean(probas, axis=2)\n",
    "    \n",
    "    def _fit_final(self, probas, y):\n",
    "        if not self._layer_fitted:\n",
    "            raise Exception(\"Intermediate estimators not fitted.\")\n",
    "        self.final_clf.fit(probas, y)\n",
    "        print(\"Final classifier fitted\")\n",
    "        self._final_fitted = True\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self._fit_transformer(X, y)\n",
    "        self._layer_probas = self._fit_layer(X, y)\n",
    "        self._fit_final(self._layer_probas, y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self._layer_fitted:\n",
    "            raise Exception(\"Intermediate estimators not fitted.\")\n",
    "        if not self._final_fitted:\n",
    "            raise Exception(\"Final classifier not fitted.\")\n",
    "        probas = self._predict_layer_probas(X)\n",
    "        return self.final_clf.predict_proba(probas)[:, 1]\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        if not self._layer_fitted:\n",
    "            raise Exception(\"Intermediate estimators not fitted.\")\n",
    "        if not self._final_fitted:\n",
    "            raise Exception(\"Final classifier not fitted.\")\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stack_full = StackingClassifier(clfs_full, LogisticRegression(), transformer=pipe_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/3\n",
      "    Estimator 'rf25'\n",
      "    Estimator 'rf40'\n",
      "    Estimator 'logreg1'\n",
      "    Estimator 'logreg3'\n",
      "Fold 2/3\n",
      "    Estimator 'rf25'\n",
      "    Estimator 'rf40'\n",
      "    Estimator 'logreg1'\n",
      "    Estimator 'logreg3'\n",
      "Fold 3/3\n",
      "    Estimator 'rf25'\n",
      "    Estimator 'rf40'\n",
      "    Estimator 'logreg1'\n",
      "    Estimator 'logreg3'\n",
      "Final classifier fitted\n"
     ]
    }
   ],
   "source": [
    "stack_full.fit(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr = stack_full.predict_proba(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58036,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_full.predict(X_full, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation set predictions\n",
    "Xv_full, Xv_nan, yv_full, yv_nan, idxv_full, idxv_nan = preprocess(X_val, y_val)\n",
    "preds_full = pipe_full.predict(Xv_full)\n",
    "probas_full = pipe_full.predict_proba(Xv_full)\n",
    "preds_nan = pipe_nan.predict(Xv_nan)\n",
    "probas_nan = pipe_nan.predict_proba(Xv_nan)\n",
    "y_pred = reconstruct([preds_full, preds_nan], [idxv_full, idxv_nan])\n",
    "y_probas = reconstruct([probas_full, probas_nan], [idxv_full, idxv_nan])\n",
    "\n",
    "# Evaluation\n",
    "confusion = metrics.confusion_matrix(y_val, y_pred)\n",
    "loss = metrics.log_loss(y_val, y_probas)\n",
    "print(\"Confusion matrix\")\n",
    "print(tabulate(confusion, tablefmt=\"fancy_grid\"))\n",
    "print(\"Log-loss: {:0.4f}\".format(loss))\n",
    "\n",
    "# Prediction\n",
    "X_test = pd.read_csv('test.csv')\n",
    "X_test_ID = X_test.ID.copy()\n",
    "X_test.drop(['ID'], axis=1, inplace=True)\n",
    "Xt_full, Xt_nan, _, _, idxt_full, idxt_nan = preprocess(X_test)\n",
    "probas_full = pipe_full.predict_proba(Xt_full)\n",
    "probas_nan = pipe_nan.predict_proba(Xt_nan)\n",
    "y_probas = reconstruct([probas_full, probas_nan], [idxt_full, idxt_nan])\n",
    "y_probas_df = pd.DataFrame({'ID': X_test_ID, 'PredictedProb': y_probas[:, 1]})\n",
    "y_probas_df.to_csv('submission.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
